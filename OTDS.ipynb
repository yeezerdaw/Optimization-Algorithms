{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Descent\n",
    "\n",
    "    \n",
    "    Parameters:\n",
    "    - f: function to minimize.\n",
    "    - grad_f: gradient of the function.\n",
    "    - x0: initial guess (numpy array).\n",
    "    - alpha_func: function to determine the step size.\n",
    "    - tol: tolerance for convergence (default: 1e-6).\n",
    "    - max_iter: maximum number of iterations (default: 1000).\n",
    "    \n",
    "    Returns:\n",
    "    - x: optimized value of x.\n",
    "    - f(x): function value at the optimized x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized x: [3.138550867693342e-06, 3.138550867693342e-06]\n",
      "Function value at optimized x: 1.9701003098197258e-11\n"
     ]
    }
   ],
   "source": [
    "def dot_product(v1, v2):\n",
    "\n",
    "    return sum(x*y for x, y in zip(v1, v2))\n",
    "\n",
    "def vector_add(v1, v2):\n",
    "\n",
    "    return [x + y for x, y in zip(v1, v2)]\n",
    "\n",
    "def vector_subtract(v1, v2):\n",
    "\n",
    "    return [x - y for x, y in zip(v1, v2)]\n",
    "\n",
    "def scalar_multiply(scalar, vector):\n",
    "\n",
    "    return [scalar * x for x in vector]\n",
    "\n",
    "def vector_norm(v):\n",
    "\n",
    "    return sum(x**2 for x in v) ** 0.5\n",
    "\n",
    "def generic_descent(f, grad_f, x0, tol=1e-6, max_iter=1000):\n",
    "    x = x0\n",
    "    k = 0\n",
    "    while k < max_iter:\n",
    "        d = scalar_multiply(-1, grad_f(x))\n",
    "        if dot_product(grad_f(x), d) >= 0:\n",
    "            d = scalar_multiply(-1, grad_f(x))\n",
    "\n",
    "        alpha = 0.1\n",
    "        x_new = vector_add(x, scalar_multiply(alpha, d))\n",
    "\n",
    "        if vector_norm(vector_subtract(x_new, x)) < tol:\n",
    "            break\n",
    "\n",
    "        x = x_new\n",
    "        k += 1\n",
    "\n",
    "    return x, f(x)\n",
    "\n",
    "def func(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "def grad_func(x):\n",
    "    return [2*x[0], 2*x[1]]\n",
    "\n",
    "\n",
    "x0 = [5, 5]\n",
    "\n",
    "optimal_x, optimal_value = generic_descent(func, grad_func, x0)\n",
    "\n",
    "print(\"Optimized x:\", optimal_x)\n",
    "print(\"Function value at optimized x:\", optimal_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the function's minimum is located near the origin (0,0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized x: [3.3699933333938316e-07, 3.3699933333938316e-07]\n",
      "Function value at optimized x: 2.2713710134237736e-13\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(f, grad_f, x0, alpha=0.1, tol=1e-6, max_iter=1000):\n",
    "    \n",
    "    x = x0\n",
    "    k = 0\n",
    "\n",
    " \n",
    "    while vector_norm(grad_f(x)) > tol and k < max_iter:\n",
    "  \n",
    "        grad = grad_f(x)\n",
    "\n",
    "        x[0] = x[0] - alpha * grad[0]\n",
    "        x[1] = x[1] - alpha * grad[1]\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return x, f(x)\n",
    "\n",
    "def func(x):\n",
    "\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "def grad_func(x):\n",
    "\n",
    "    return [2*x[0], 2*x[1]]\n",
    "\n",
    "def vector_norm(v):\n",
    "\n",
    "    return sum(x**2 for x in v) ** 0.5\n",
    "\n",
    "\n",
    "x0 = [5, 5]\n",
    "alpha = 0.1  \n",
    "tolerance = 1e-6\n",
    "\n",
    "\n",
    "optimal_x, optimal_value = gradient_descent(func, grad_func, x0, alpha, tolerance)\n",
    "\n",
    "print(\"Optimized x:\", optimal_x)\n",
    "print(\"Function value at optimized x:\", optimal_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
